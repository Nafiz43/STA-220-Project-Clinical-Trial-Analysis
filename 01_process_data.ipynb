{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pancreatic_cancer\n",
      "2572\n",
      "chagas_disease\n",
      "55\n",
      "endometriosis\n",
      "588\n",
      "drug_resistant_tuberculosis\n",
      "60\n",
      "duchenne_muscular_dystrophy\n",
      "361\n",
      "3636\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read a JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "diseases = [\n",
    "    \"pancreatic_cancer_clinical_trials\",\n",
    "    \"chagas_disease_clinical_trials\",\n",
    "    \"endometriosis_clinical_trials\",\n",
    "    \"drug_resistant_tuberculosis_clinical_trials\",\n",
    "    \"duchenne_muscular_dystrophy_clinical_trials\",\n",
    "]\n",
    "\n",
    "master_df = df = pd.DataFrame()\n",
    "\n",
    "for disease_to_consider in diseases:\n",
    "    # Example usage\n",
    "    file_path = \"data/\"+disease_to_consider+\".json\"  # Replace with your JSON file path\n",
    "    studies = read_json_file(file_path)\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for batch_study in studies:\n",
    "        for study in batch_study:\n",
    "                # Safely access nested keys\n",
    "                nctId = study['protocolSection']['identificationModule'].get('nctId', 'Unknown')\n",
    "                overallStatus = study['protocolSection']['statusModule'].get('overallStatus', 'Unknown')\n",
    "                startDate = study['protocolSection']['statusModule'].get('startDateStruct', {}).get('date', 'Unknown Date')\n",
    "                try:\n",
    "                     conditions = ', '.join(study['protocolSection']['conditionsModule'].get('conditions', ['No conditions listed']))\n",
    "                except:\n",
    "                     conditions = \"No conditions listed\"\n",
    "                     \n",
    "                acronym = study['protocolSection']['identificationModule'].get('acronym', 'Unknown')\n",
    "\n",
    "                # Extract interventions safely\n",
    "                interventions_list = study['protocolSection'].get('armsInterventionsModule', {}).get('interventions', [])\n",
    "                interventions = ', '.join([intervention.get('name', 'No intervention name listed') for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "\n",
    "                # Extract locations safely\n",
    "                locations_list = study['protocolSection'].get('contactsLocationsModule', {}).get('locations', [])\n",
    "                locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "\n",
    "                # Extract dates and phases\n",
    "                primaryCompletionDate = study['protocolSection']['statusModule'].get('primaryCompletionDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyFirstPostDate = study['protocolSection']['statusModule'].get('studyFirstPostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                lastUpdatePostDate = study['protocolSection']['statusModule'].get('lastUpdatePostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyType = study['protocolSection']['designModule'].get('studyType', 'Unknown')\n",
    "                phases = ', '.join(study['protocolSection']['designModule'].get('phases', ['Not Available']))\n",
    "                phases = phases.split(\",\")[-1].strip()\n",
    "                if(phases == \"EARLY_PHASE1\"):\n",
    "                     phases = \"PHASE1\"\n",
    "\n",
    "                # phases = get_highest_phase(study)\n",
    "                lead_sponsor_name = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('name', 'Unknown Sponsor')\n",
    "                lead_sponsor_type = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('class', 'Unknown Sponsor Type')\n",
    "\n",
    "                disease_to_consider = disease_to_consider.replace(\"_clinical_trials\", \"\")\n",
    "\n",
    "                # Append the data to the list as a dictionary\n",
    "                data_list.append({\n",
    "                    \"NCT ID\": nctId,\n",
    "                    \"Acronym\": acronym,\n",
    "                    \"Overall Status\": overallStatus,\n",
    "                    \"Start Date\": startDate,\n",
    "                    \"Conditions\": conditions,\n",
    "                    \"Interventions\": interventions,\n",
    "                    \"Locations\": locations,\n",
    "                    \"Primary Completion Date\": primaryCompletionDate,\n",
    "                    \"Study First Post Date\": studyFirstPostDate,\n",
    "                    \"Last Update Post Date\": lastUpdatePostDate,\n",
    "                    \"Study Type\": studyType,\n",
    "                    \"Phases\": phases,\n",
    "                    \"Sponsor\": lead_sponsor_name,\n",
    "                    \"Sponsor Type\": lead_sponsor_type,\n",
    "                    \"Disease\": disease_to_consider.replace(\" \", \"_\")\n",
    "                })\n",
    "\n",
    "    print(disease_to_consider)\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # print(df)\n",
    "    print(len(df))\n",
    "    os.makedirs(\"data/\", exist_ok=True)\n",
    "    # df.to_csv(\"data/\"+disease_to_consider.replace(\" \", \"_\")+\"_procesed.csv\", index=False)\n",
    "    master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "master_df.to_csv(\"data/all_disease_procesed.csv\", index=False)\n",
    "print(len(master_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2169 records for alzheimer's\n",
      "Processed 2303 records for influenza\n",
      "Processed 5000 records for breast cancer\n",
      "Processed 3517 records for hepatitis\n",
      "Processed 1129 records for malaria\n",
      "Total records saved: 14118\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read a JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# List of diseases to consider\n",
    "diseases = [\n",
    "    \"alzheimer's\",\n",
    "    \"influenza\",\n",
    "    \"breast cancer\",\n",
    "    \"hepatitis\",\n",
    "    \"malaria\",\n",
    "]\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for disease_to_consider in diseases:\n",
    "    file_path = f\"data/{disease_to_consider}.json\"\n",
    "    \n",
    "    # Check if file exists before proceeding\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    studies = read_json_file(file_path)\n",
    "    data_list = []\n",
    "\n",
    "    # Ensure batch processing works correctly\n",
    "    for study in studies:\n",
    "        if not isinstance(study, dict):\n",
    "            print(f\"Skipping invalid study format in {disease_to_consider}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            protocol = study.get(\"protocolSection\", {})\n",
    "            identification = protocol.get(\"identificationModule\", {})\n",
    "            status = protocol.get(\"statusModule\", {})\n",
    "            conditions_module = protocol.get(\"conditionsModule\", {})\n",
    "            design = protocol.get(\"designModule\", {})\n",
    "            interventions_module = protocol.get(\"armsInterventionsModule\", {})\n",
    "            locations_module = protocol.get(\"contactsLocationsModule\", {})\n",
    "            sponsor_module = protocol.get(\"sponsorCollaboratorsModule\", {}).get(\"leadSponsor\", {})\n",
    "\n",
    "            nctId = identification.get(\"nctId\", \"Unknown\")\n",
    "            overallStatus = status.get(\"overallStatus\", \"Unknown\")\n",
    "            startDate = status.get(\"startDateStruct\", {}).get(\"date\", \"Unknown Date\")\n",
    "            conditions = ', '.join(conditions_module.get(\"conditions\", [\"No conditions listed\"]))\n",
    "            acronym = identification.get(\"acronym\", \"Unknown\")\n",
    "\n",
    "            # Extract interventions safely\n",
    "            interventions_list = interventions_module.get(\"interventions\", [])\n",
    "            interventions = ', '.join([intervention.get(\"name\", \"No intervention name listed\") for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "\n",
    "            # Extract locations safely\n",
    "            locations_list = locations_module.get(\"locations\", [])\n",
    "            locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "\n",
    "            primaryCompletionDate = status.get(\"primaryCompletionDateStruct\", {}).get(\"date\", \"Unknown Date\")\n",
    "            studyFirstPostDate = status.get(\"studyFirstPostDateStruct\", {}).get(\"date\", \"Unknown Date\")\n",
    "            lastUpdatePostDate = status.get(\"lastUpdatePostDateStruct\", {}).get(\"date\", \"Unknown Date\")\n",
    "            studyType = design.get(\"studyType\", \"Unknown\")\n",
    "            phases = ', '.join(design.get(\"phases\", [\"Not Available\"]))\n",
    "            phases = phases.split(\",\")[-1].strip()\n",
    "            if phases == \"EARLY_PHASE1\":\n",
    "                phases = \"PHASE1\"\n",
    "\n",
    "            lead_sponsor_name = sponsor_module.get(\"name\", \"Unknown Sponsor\")\n",
    "            lead_sponsor_type = sponsor_module.get(\"class\", \"Unknown Sponsor Type\")\n",
    "\n",
    "            disease_name = disease_to_consider.replace(\"_clinical_trials\", \"\").replace(\" \", \"_\")\n",
    "\n",
    "            data_list.append({\n",
    "                \"NCT ID\": nctId,\n",
    "                \"Acronym\": acronym,\n",
    "                \"Overall Status\": overallStatus,\n",
    "                \"Start Date\": startDate,\n",
    "                \"Conditions\": conditions,\n",
    "                \"Interventions\": interventions,\n",
    "                \"Locations\": locations,\n",
    "                \"Primary Completion Date\": primaryCompletionDate,\n",
    "                \"Study First Post Date\": studyFirstPostDate,\n",
    "                \"Last Update Post Date\": lastUpdatePostDate,\n",
    "                \"Study Type\": studyType,\n",
    "                \"Phases\": phases,\n",
    "                \"Sponsor\": lead_sponsor_name,\n",
    "                \"Sponsor Type\": lead_sponsor_type,\n",
    "                \"Disease\": disease_name\n",
    "            })\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping a study due to missing key: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    print(f\"Processed {len(df)} records for {disease_to_consider}\")\n",
    "\n",
    "    os.makedirs(\"data/\", exist_ok=True)\n",
    "    df.to_csv(f\"data/{disease_to_consider.replace(' ', '_')}_processed.csv\", index=False)\n",
    "    master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset\n",
    "master_df.to_csv(\"data/all_disease_processed.csv\", index=False)\n",
    "print(f\"Total records saved: {len(master_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the collected JSON files\n",
    "### Clinical Trials\n",
    "Removed the \"DetailedDescription\" key as it is not needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('duchenne muscular dystrophy.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print JSON content\n",
    "print(data)\n",
    "\n",
    "def remove_description_module(data):\n",
    "    # Count the number of outer lists\n",
    "    num_outer_lists = len(data)\n",
    "    # print(f\"Number of outer lists: {num_outer_lists}\")\n",
    "    \n",
    "    # Traverse the outer list\n",
    "    for i, outer_item in enumerate(data):\n",
    "        # print(f\"Processing outer list {i+1}/{num_outer_lists}\")\n",
    "        \n",
    "        # Ensure it's a list before iterating\n",
    "        if isinstance(outer_item, list):\n",
    "            for j, inner_item in enumerate(outer_item):\n",
    "                # print(f\"Processing inner list {j+1}/{len(outer_item)} in outer list {i+1}\")\n",
    "                \n",
    "                # Ensure the structure matches expected format\n",
    "                if isinstance(inner_item, dict) and \"protocolSection\" in inner_item:\n",
    "                    if \"descriptionModule\" in inner_item[\"protocolSection\"]:\n",
    "                        del inner_item[\"protocolSection\"][\"descriptionModule\"]\n",
    "                        # print(f\"Removed 'descriptionModule' from inner list {j+1} in outer list {i+1}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load JSON data (replace with actual data loading)\n",
    "\n",
    "# Process the data\n",
    "data = remove_description_module(data)\n",
    "\n",
    "# Print or save modified JSON\n",
    "# print(json.dumps(data, indent=2))\n",
    "# Save the modified data back to a file\n",
    "with open('data/duchenne_muscular_dystrophy_clinical_trials.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "# diseases = [\n",
    "#     \"pancreatic_cancer_clinical_trials\",\n",
    "#     \"chagas_disease_clinical_trials\",\n",
    "#     \"endometriosis_clinical_trials\",\n",
    "#     \"drug_resistant_tuberculosis_clinical_trials\",\n",
    "#     \"duchenne_muscular_dystrophy_clinical_trials\",\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Pubmed Data\n",
    "\n",
    "cleaned [\"copyrights\", \"doi\", \"authors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Pubmed_Pancreatic_Cancer.csv 9831\n",
      "Number of instances in Pubmed_Duchenne_Muscular_Dystrophy.csv 1423\n",
      "Number of instances in Pubmed_Chagas_Disease.csv 680\n",
      "Number of instances in Pubmed_Endometriosis.csv 2839\n",
      "Number of instances in Pubmed_Drug_Resistant_Tuberculosis.csv 1274\n",
      "all_pubmed 16047\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory = \"data/\"  # Change this to your actual directory\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"Directory '{directory}' does not exist.\")\n",
    "    exit()\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "# Process all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"all_\"):\n",
    "        continue  # Skip hidden files\n",
    "\n",
    "    if filename.endswith(\".csv\"):  # Only process CSV files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load CSV\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Remove specified columns if they exist\n",
    "        columns_to_remove = [\"copyrights\", \"doi\", \"authors\"]\n",
    "        try:\n",
    "            df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)\n",
    "        except:\n",
    "            print(\"Error in removing columns\")\n",
    "        \n",
    "        # Save back to the same file\n",
    "        df['category']= filename\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(\"Number of instances in \"+filename, len(df))\n",
    "        master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "master_df.to_csv('data/all_pubmed.csv', index=False)\n",
    "print(\"all_pubmed\",len(master_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
