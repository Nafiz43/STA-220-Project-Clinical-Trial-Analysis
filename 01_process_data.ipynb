{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pancreatic_cancer\n",
      "2572\n",
      "chagas_disease\n",
      "55\n",
      "endometriosis\n",
      "588\n",
      "drug_resistant_tuberculosis\n",
      "60\n",
      "duchenne_muscular_dystrophy\n",
      "361\n",
      "3636\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read a JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "diseases = [\n",
    "    \"pancreatic_cancer_clinical_trials\",\n",
    "    \"chagas_disease_clinical_trials\",\n",
    "    \"endometriosis_clinical_trials\",\n",
    "    \"drug_resistant_tuberculosis_clinical_trials\",\n",
    "    \"duchenne_muscular_dystrophy_clinical_trials\",\n",
    "]\n",
    "\n",
    "master_df = df = pd.DataFrame()\n",
    "\n",
    "for disease_to_consider in diseases:\n",
    "    # Example usage\n",
    "    file_path = \"data/\"+disease_to_consider+\".json\"  # Replace with your JSON file path\n",
    "    studies = read_json_file(file_path)\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for batch_study in studies:\n",
    "        for study in batch_study:\n",
    "                # Safely access nested keys\n",
    "                nctId = study['protocolSection']['identificationModule'].get('nctId', 'Unknown')\n",
    "                overallStatus = study['protocolSection']['statusModule'].get('overallStatus', 'Unknown')\n",
    "                startDate = study['protocolSection']['statusModule'].get('startDateStruct', {}).get('date', 'Unknown Date')\n",
    "                try:\n",
    "                     conditions = ', '.join(study['protocolSection']['conditionsModule'].get('conditions', ['No conditions listed']))\n",
    "                except:\n",
    "                     conditions = \"No conditions listed\"\n",
    "                     \n",
    "                acronym = study['protocolSection']['identificationModule'].get('acronym', 'Unknown')\n",
    "\n",
    "                # Extract interventions safely\n",
    "                interventions_list = study['protocolSection'].get('armsInterventionsModule', {}).get('interventions', [])\n",
    "                interventions = ', '.join([intervention.get('name', 'No intervention name listed') for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "\n",
    "                # Extract locations safely\n",
    "                locations_list = study['protocolSection'].get('contactsLocationsModule', {}).get('locations', [])\n",
    "                locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "\n",
    "                # Extract dates and phases\n",
    "                primaryCompletionDate = study['protocolSection']['statusModule'].get('primaryCompletionDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyFirstPostDate = study['protocolSection']['statusModule'].get('studyFirstPostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                lastUpdatePostDate = study['protocolSection']['statusModule'].get('lastUpdatePostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyType = study['protocolSection']['designModule'].get('studyType', 'Unknown')\n",
    "                phases = ', '.join(study['protocolSection']['designModule'].get('phases', ['Not Available']))\n",
    "                phases = phases.split(\",\")[-1].strip()\n",
    "                if(phases == \"EARLY_PHASE1\"):\n",
    "                     phases = \"PHASE1\"\n",
    "\n",
    "                # phases = get_highest_phase(study)\n",
    "                lead_sponsor_name = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('name', 'Unknown Sponsor')\n",
    "                lead_sponsor_type = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('class', 'Unknown Sponsor Type')\n",
    "\n",
    "                disease_to_consider = disease_to_consider.replace(\"_clinical_trials\", \"\")\n",
    "\n",
    "                # Append the data to the list as a dictionary\n",
    "                data_list.append({\n",
    "                    \"NCT ID\": nctId,\n",
    "                    \"Acronym\": acronym,\n",
    "                    \"Overall Status\": overallStatus,\n",
    "                    \"Start Date\": startDate,\n",
    "                    \"Conditions\": conditions,\n",
    "                    \"Interventions\": interventions,\n",
    "                    \"Locations\": locations,\n",
    "                    \"Primary Completion Date\": primaryCompletionDate,\n",
    "                    \"Study First Post Date\": studyFirstPostDate,\n",
    "                    \"Last Update Post Date\": lastUpdatePostDate,\n",
    "                    \"Study Type\": studyType,\n",
    "                    \"Phases\": phases,\n",
    "                    \"Sponsor\": lead_sponsor_name,\n",
    "                    \"Sponsor Type\": lead_sponsor_type,\n",
    "                    \"Disease\": disease_to_consider.replace(\" \", \"_\")\n",
    "                })\n",
    "\n",
    "    print(disease_to_consider)\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # print(df)\n",
    "    print(len(df))\n",
    "    os.makedirs(\"data/\", exist_ok=True)\n",
    "    # df.to_csv(\"data/\"+disease_to_consider.replace(\" \", \"_\")+\"_procesed.csv\", index=False)\n",
    "    master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "master_df.to_csv(\"data/all_disease_procesed.csv\", index=False)\n",
    "print(len(master_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the collected JSON files\n",
    "### Clinical Trials\n",
    "Removed the \"DetailedDescription\" key as it is not needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('duchenne muscular dystrophy.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print JSON content\n",
    "print(data)\n",
    "\n",
    "def remove_description_module(data):\n",
    "    # Count the number of outer lists\n",
    "    num_outer_lists = len(data)\n",
    "    # print(f\"Number of outer lists: {num_outer_lists}\")\n",
    "    \n",
    "    # Traverse the outer list\n",
    "    for i, outer_item in enumerate(data):\n",
    "        # print(f\"Processing outer list {i+1}/{num_outer_lists}\")\n",
    "        \n",
    "        # Ensure it's a list before iterating\n",
    "        if isinstance(outer_item, list):\n",
    "            for j, inner_item in enumerate(outer_item):\n",
    "                # print(f\"Processing inner list {j+1}/{len(outer_item)} in outer list {i+1}\")\n",
    "                \n",
    "                # Ensure the structure matches expected format\n",
    "                if isinstance(inner_item, dict) and \"protocolSection\" in inner_item:\n",
    "                    if \"descriptionModule\" in inner_item[\"protocolSection\"]:\n",
    "                        del inner_item[\"protocolSection\"][\"descriptionModule\"]\n",
    "                        # print(f\"Removed 'descriptionModule' from inner list {j+1} in outer list {i+1}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load JSON data (replace with actual data loading)\n",
    "\n",
    "# Process the data\n",
    "data = remove_description_module(data)\n",
    "\n",
    "# Print or save modified JSON\n",
    "# print(json.dumps(data, indent=2))\n",
    "# Save the modified data back to a file\n",
    "with open('data/duchenne_muscular_dystrophy_clinical_trials.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "# diseases = [\n",
    "#     \"pancreatic_cancer_clinical_trials\",\n",
    "#     \"chagas_disease_clinical_trials\",\n",
    "#     \"endometriosis_clinical_trials\",\n",
    "#     \"drug_resistant_tuberculosis_clinical_trials\",\n",
    "#     \"duchenne_muscular_dystrophy_clinical_trials\",\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Pubmed Data\n",
    "\n",
    "cleaned [\"copyrights\", \"doi\", \"authors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Pubmed_Pancreatic_Cancer.csv 9831\n",
      "Number of instances in Pubmed_Duchenne_Muscular_Dystrophy.csv 1423\n",
      "Number of instances in Pubmed_Chagas_Disease.csv 680\n",
      "Number of instances in Pubmed_Endometriosis.csv 2839\n",
      "Number of instances in Pubmed_Drug_Resistant_Tuberculosis.csv 1274\n",
      "all_pubmed 16047\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory = \"data/\"  # Change this to your actual directory\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"Directory '{directory}' does not exist.\")\n",
    "    exit()\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "# Process all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"all_\"):\n",
    "        continue  # Skip hidden files\n",
    "\n",
    "    if filename.endswith(\".csv\"):  # Only process CSV files\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load CSV\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Remove specified columns if they exist\n",
    "        columns_to_remove = [\"copyrights\", \"doi\", \"authors\"]\n",
    "        try:\n",
    "            df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)\n",
    "        except:\n",
    "            print(\"Error in removing columns\")\n",
    "        \n",
    "        # Save back to the same file\n",
    "        df['category']= filename\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(\"Number of instances in \"+filename, len(df))\n",
    "        master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "master_df.to_csv('data/all_pubmed.csv', index=False)\n",
    "print(\"all_pubmed\",len(master_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
