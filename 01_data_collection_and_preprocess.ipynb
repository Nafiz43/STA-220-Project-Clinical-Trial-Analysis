{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_description_module(data):\n",
    "    # Count the number of outer lists\n",
    "    num_outer_lists = len(data)\n",
    "    # print(f\"Number of outer lists: {num_outer_lists}\")\n",
    "    \n",
    "    # Traverse the outer list\n",
    "    for i, outer_item in enumerate(data):\n",
    "        # print(f\"Processing outer list {i+1}/{num_outer_lists}\")\n",
    "        \n",
    "        # Ensure it's a list before iterating\n",
    "        if isinstance(outer_item, list):\n",
    "            for j, inner_item in enumerate(outer_item):\n",
    "                # print(f\"Processing inner list {j+1}/{len(outer_item)} in outer list {i+1}\")\n",
    "                \n",
    "                # Ensure the structure matches expected format\n",
    "                if isinstance(inner_item, dict) and \"protocolSection\" in inner_item:\n",
    "                    if \"descriptionModule\" in inner_item[\"protocolSection\"]:\n",
    "                        del inner_item[\"protocolSection\"][\"descriptionModule\"]\n",
    "                        # print(f\"Removed 'descriptionModule' from inner list {j+1} in outer list {i+1}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "diseases = [\n",
    "    \"pancreatic cancer\",\n",
    "    \"chagas disease\",\n",
    "    \"endometriosis\",\n",
    "    \"drug resistant tuberculosis\",\n",
    "    \"duchenne muscular dystrophy\",\n",
    "    \"alzheimer's\",\n",
    "    \"influenza\",\n",
    "    \"hepatitis\",\n",
    "    \"malaria\",\n",
    "    \"breast-cancer\",\n",
    "]\n",
    "\n",
    "\n",
    "# disease_to_consider = diseases[1]\n",
    "\n",
    "for disease_to_consider in diseases:\n",
    "\n",
    "    # Initial URL for the first API call\n",
    "    base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "    params = {\n",
    "        \"query.titles\": disease_to_consider,\n",
    "        \"pageSize\": 100\n",
    "    }\n",
    "\n",
    "    # Initialize an empty list to store the data\n",
    "    data_list = []\n",
    "    all_data = []\n",
    "\n",
    "\n",
    "    # Loop until there is no nextPageToken\n",
    "    x=1\n",
    "    while True:\n",
    "        if x>50:\n",
    "            break\n",
    "\n",
    "        x = x+1\n",
    "        # Print the current URL (for debugging purposes)\n",
    "        print(\"Fetching data from:\", base_url + '?' + '&'.join([f\"{k}={v}\" for k, v in params.items()]))\n",
    "\n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()  # Parse JSON response\n",
    "            studies = data.get('studies', [])  # Extract the list of studies\n",
    "            all_data.append(studies)\n",
    "            # print(data)        \n",
    "\n",
    "            # Check for nextPageToken and update the params or break the loop\n",
    "            nextPageToken = data.get('nextPageToken')\n",
    "            if nextPageToken:\n",
    "                params['pageToken'] = nextPageToken  # Set the pageToken for the next request\n",
    "            else:\n",
    "                break  # Exit the loop if no nextPageToken is present\n",
    "        else:\n",
    "            print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "            break\n",
    "        print(len(all_data))\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "    # Cleaning the collected data\n",
    "    all_data = remove_description_module(all_data)\n",
    "\n",
    "    print(all_data)\n",
    "\n",
    "    with open(\"data/CT_\"+disease_to_consider+\".json\", \"w\") as json_file:\n",
    "        json.dump(all_data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing for RARE Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2580 records for CT_pancreatic cancer\n",
      "Found 55 records for CT_chagas disease\n",
      "Found 589 records for CT_endometriosis\n",
      "Found 60 records for CT_drug resistant tuberculosis\n",
      "Found 364 records for CT_duchenne muscular dystrophy\n",
      "Total records processed for RARE Disease 3648\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read a JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "diseases = [\n",
    "    \"CT_pancreatic cancer\",\n",
    "    \"CT_chagas disease\",\n",
    "    \"CT_endometriosis\",\n",
    "    \"CT_drug resistant tuberculosis\",\n",
    "    \"CT_duchenne muscular dystrophy\",\n",
    "]\n",
    "\n",
    "\n",
    "master_df = df = pd.DataFrame()\n",
    "\n",
    "for disease_to_consider in diseases:\n",
    "    # Example usage\n",
    "    file_path = \"data/\"+disease_to_consider+\".json\"\n",
    "    studies = read_json_file(file_path)\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for batch_study in studies:\n",
    "        for study in batch_study:\n",
    "                # Safely access nested keys\n",
    "                nctId = study['protocolSection']['identificationModule'].get('nctId', 'Unknown')\n",
    "                overallStatus = study['protocolSection']['statusModule'].get('overallStatus', 'Unknown')\n",
    "                startDate = study['protocolSection']['statusModule'].get('startDateStruct', {}).get('date', 'Unknown Date')\n",
    "                try:\n",
    "                     conditions = ', '.join(study['protocolSection']['conditionsModule'].get('conditions', ['No conditions listed']))\n",
    "                except:\n",
    "                     conditions = \"No conditions listed\"\n",
    "                     \n",
    "                acronym = study['protocolSection']['identificationModule'].get('acronym', 'Unknown')\n",
    "\n",
    "                # Extract interventions safely\n",
    "                interventions_list = study['protocolSection'].get('armsInterventionsModule', {}).get('interventions', [])\n",
    "                interventions = ', '.join([intervention.get('name', 'No intervention name listed') for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "\n",
    "                # Extract locations safely\n",
    "                locations_list = study['protocolSection'].get('contactsLocationsModule', {}).get('locations', [])\n",
    "                locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "\n",
    "                # Extract dates and phases\n",
    "                primaryCompletionDate = study['protocolSection']['statusModule'].get('primaryCompletionDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyFirstPostDate = study['protocolSection']['statusModule'].get('studyFirstPostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                lastUpdatePostDate = study['protocolSection']['statusModule'].get('lastUpdatePostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyType = study['protocolSection']['designModule'].get('studyType', 'Unknown')\n",
    "                phases = ', '.join(study['protocolSection']['designModule'].get('phases', ['Not Available']))\n",
    "                phases = phases.split(\",\")[-1].strip()\n",
    "                if(phases == \"EARLY_PHASE1\"):\n",
    "                     phases = \"PHASE1\"\n",
    "\n",
    "                # phases = get_highest_phase(study)\n",
    "                lead_sponsor_name = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('name', 'Unknown Sponsor')\n",
    "                lead_sponsor_type = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('class', 'Unknown Sponsor Type')\n",
    "\n",
    "                disease_to_consider = disease_to_consider.replace(\"_clinical_trials\", \"\")\n",
    "\n",
    "                # Append the data to the list as a dictionary\n",
    "                data_list.append({\n",
    "                    \"NCT ID\": nctId,\n",
    "                    \"Acronym\": acronym,\n",
    "                    \"Overall Status\": overallStatus,\n",
    "                    \"Start Date\": startDate,\n",
    "                    \"Conditions\": conditions,\n",
    "                    \"Interventions\": interventions,\n",
    "                    \"Locations\": locations,\n",
    "                    \"Primary Completion Date\": primaryCompletionDate,\n",
    "                    \"Study First Post Date\": studyFirstPostDate,\n",
    "                    \"Last Update Post Date\": lastUpdatePostDate,\n",
    "                    \"Study Type\": studyType,\n",
    "                    \"Phases\": phases,\n",
    "                    \"Sponsor\": lead_sponsor_name,\n",
    "                    \"Sponsor Type\": lead_sponsor_type,\n",
    "                    \"Disease\": disease_to_consider.replace(\" \", \"_\")\n",
    "                })\n",
    "\n",
    "    # print(disease_to_consider)\n",
    "    print(f\"Found {len(data_list)} records for {disease_to_consider}\")\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # print(df)\n",
    "    # print(len(df))\n",
    "    os.makedirs(\"data/\", exist_ok=True)\n",
    "    # df.to_csv(\"data/\"+disease_to_consider.replace(\" \", \"_\")+\"_procesed.csv\", index=False)\n",
    "    master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "master_df.to_csv(\"data/CT_all_rare_disease_procesed.csv\", index=False)\n",
    "print(\"Total records processed for RARE Disease\", len(master_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing for COMMON Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2169 records for CT_alzheimer's\n",
      "Found 2303 records for CT_influenza\n",
      "Found 5000 records for CT_breast-cancer\n",
      "Found 3517 records for CT_hepatitis\n",
      "Found 1129 records for CT_malaria\n",
      "Total records processed for COMMON Disease 14118\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to read a JSON file\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "diseases = [\n",
    "    \"CT_alzheimer's\",\n",
    "    \"CT_influenza\",\n",
    "    \"CT_breast-cancer\",\n",
    "    \"CT_hepatitis\",\n",
    "    \"CT_malaria\",\n",
    "]\n",
    "\n",
    "master_df = df = pd.DataFrame()\n",
    "\n",
    "for disease_to_consider in diseases:\n",
    "    # Example usage\n",
    "    file_path = \"data/\"+disease_to_consider+\".json\"\n",
    "    studies = read_json_file(file_path)\n",
    "    data_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for batch_study in studies:\n",
    "        for study in batch_study:\n",
    "                # Safely access nested keys\n",
    "                nctId = study['protocolSection']['identificationModule'].get('nctId', 'Unknown')\n",
    "                overallStatus = study['protocolSection']['statusModule'].get('overallStatus', 'Unknown')\n",
    "                startDate = study['protocolSection']['statusModule'].get('startDateStruct', {}).get('date', 'Unknown Date')\n",
    "                try:\n",
    "                     conditions = ', '.join(study['protocolSection']['conditionsModule'].get('conditions', ['No conditions listed']))\n",
    "                except:\n",
    "                     conditions = \"No conditions listed\"\n",
    "                     \n",
    "                acronym = study['protocolSection']['identificationModule'].get('acronym', 'Unknown')\n",
    "\n",
    "                # Extract interventions safely\n",
    "                interventions_list = study['protocolSection'].get('armsInterventionsModule', {}).get('interventions', [])\n",
    "                interventions = ', '.join([intervention.get('name', 'No intervention name listed') for intervention in interventions_list]) if interventions_list else \"No interventions listed\"\n",
    "\n",
    "                # Extract locations safely\n",
    "                locations_list = study['protocolSection'].get('contactsLocationsModule', {}).get('locations', [])\n",
    "                locations = ', '.join([f\"{location.get('city', 'No City')} - {location.get('country', 'No Country')}\" for location in locations_list]) if locations_list else \"No locations listed\"\n",
    "\n",
    "                # Extract dates and phases\n",
    "                primaryCompletionDate = study['protocolSection']['statusModule'].get('primaryCompletionDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyFirstPostDate = study['protocolSection']['statusModule'].get('studyFirstPostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                lastUpdatePostDate = study['protocolSection']['statusModule'].get('lastUpdatePostDateStruct', {}).get('date', 'Unknown Date')\n",
    "                studyType = study['protocolSection']['designModule'].get('studyType', 'Unknown')\n",
    "                phases = ', '.join(study['protocolSection']['designModule'].get('phases', ['Not Available']))\n",
    "                phases = phases.split(\",\")[-1].strip()\n",
    "                if(phases == \"EARLY_PHASE1\"):\n",
    "                     phases = \"PHASE1\"\n",
    "\n",
    "                # phases = get_highest_phase(study)\n",
    "                lead_sponsor_name = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('name', 'Unknown Sponsor')\n",
    "                lead_sponsor_type = study[\"protocolSection\"][\"sponsorCollaboratorsModule\"][\"leadSponsor\"].get('class', 'Unknown Sponsor Type')\n",
    "\n",
    "                disease_to_consider = disease_to_consider.replace(\"_clinical_trials\", \"\")\n",
    "\n",
    "                # Append the data to the list as a dictionary\n",
    "                data_list.append({\n",
    "                    \"NCT ID\": nctId,\n",
    "                    \"Acronym\": acronym,\n",
    "                    \"Overall Status\": overallStatus,\n",
    "                    \"Start Date\": startDate,\n",
    "                    \"Conditions\": conditions,\n",
    "                    \"Interventions\": interventions,\n",
    "                    \"Locations\": locations,\n",
    "                    \"Primary Completion Date\": primaryCompletionDate,\n",
    "                    \"Study First Post Date\": studyFirstPostDate,\n",
    "                    \"Last Update Post Date\": lastUpdatePostDate,\n",
    "                    \"Study Type\": studyType,\n",
    "                    \"Phases\": phases,\n",
    "                    \"Sponsor\": lead_sponsor_name,\n",
    "                    \"Sponsor Type\": lead_sponsor_type,\n",
    "                    \"Disease\": disease_to_consider.replace(\" \", \"_\")\n",
    "                })\n",
    "\n",
    "    # print(disease_to_consider)\n",
    "    print(f\"Found {len(data_list)} records for {disease_to_consider}\")\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # print(df)\n",
    "    # print(len(df))\n",
    "    os.makedirs(\"data/\", exist_ok=True)\n",
    "    # df.to_csv(\"data/\"+disease_to_consider.replace(\" \", \"_\")+\"_procesed.csv\", index=False)\n",
    "    master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "master_df.to_csv(\"data/CT_all_common_disease_processed.csv\", index=False)\n",
    "print(\"Total records processed for COMMON Disease\", len(master_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pubmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymed import PubMed\n",
    "import pandas as pd\n",
    "\n",
    "diseases = [\n",
    "    \"pancreatic cancer\",\n",
    "    \"chagas disease\",\n",
    "    \"endometriosis\",\n",
    "    \"drug resistant tuberculosis\",\n",
    "    \"duchenne muscular dystrophy\",\n",
    "    \"influenza\",\n",
    "    \"breast-cancer\",\n",
    "    \"hepatitis\",\n",
    "    \"malaria\",\n",
    "    \"alzheimer\"\n",
    "]\n",
    "email = 'xxxxxxxx@gmail.com'\n",
    "pubmed = PubMed(tool=\"PubMedSearcher\", email=email)\n",
    "print(\"\\nPubMed Clinical Trials Articles:\")\n",
    "\n",
    "for disease in diseases:\n",
    "    disease_to_consider = disease\n",
    "    search_term = \"alzheimer's+clinical+trials\"\n",
    "    results = pubmed.query(search_term, max_results=10000)\n",
    "\n",
    "    articles_data = []\n",
    "\n",
    "    for article in results:\n",
    "        article_dict = article.toDict()\n",
    "        raw_authors = article_dict.get(\"authors\", [])\n",
    "        authors = \", \".join([a[\"name\"] if isinstance(a, dict) and \"name\" in a else str(a) for a in raw_authors]) if raw_authors else None\n",
    "\n",
    "        articles_data.append({\n",
    "            \"pubmed_id\": article_dict.get(\"pubmed_id\", \"\").partition('\\n')[0],\n",
    "            \"title\": article_dict.get(\"title\", None),\n",
    "            \"keywords\": \", \".join(article_dict.get(\"keywords\", [])) if article_dict.get(\"keywords\") else None,\n",
    "            \"journal\": article_dict.get(\"journal\", None),\n",
    "            \"abstract\": article_dict.get(\"abstract\", None),\n",
    "            # \"methods\": article_dict.get(\"methods\", None),\n",
    "            # \"results\": article_dict.get(\"results\", None),\n",
    "            # \"conclusions\": article_dict.get(\"conclusions\", None),\n",
    "            # \"copyrights\": article_dict.get(\"copyrights\", None),\n",
    "            # \"doi\": article_dict.get(\"doi\", None),\n",
    "            \"publication_date\": article_dict.get(\"publication_date\", None),\n",
    "            # \"authors\": authors\n",
    "        })\n",
    "\n",
    "    df_articles = pd.DataFrame(articles_data)\n",
    "    # print(df_articles.head()) \n",
    "    df_articles.to_csv(\"data/Pubmed_\"+disease_to_consider+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Pubmed_Pancreatic_Cancer.csv 9831\n",
      "Number of instances in Pubmed_influenza.csv 8905\n",
      "Number of instances in Pubmed_pancreatic cancer.csv 60\n",
      "Number of instances in Pubmed_Chagas_Disease.csv 680\n",
      "Number of instances in Pubmed_malaria.csv 6855\n",
      "Number of instances in Pubmed_Endometriosis.csv 2839\n",
      "Number of instances in Pubmed_breast-cancer.csv 171\n",
      "Number of instances in Pubmed_chagas disease.csv 60\n",
      "Number of instances in Pubmed_Duchenne_Muscular_Dystrophy.csv 1423\n",
      "Number of instances in Pubmed_hepatitis.csv 7087\n",
      "Number of instances in Pubmed_alzheimer.csv 60\n",
      "Number of instances in Pubmed_Drug_Resistant_Tuberculosis.csv 1274\n",
      "Pubmed Data:\n",
      "all_pubmed 39245\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory = \"data/\"  # Change this to your actual directory\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"Directory '{directory}' does not exist.\")\n",
    "    exit()\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "# Process all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"Pubmed_\"):\n",
    "        if filename.endswith(\".csv\"):  # Only process CSV files\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            \n",
    "            # Load CSV\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Remove specified columns if they exist\n",
    "            columns_to_remove = [\"copyrights\", \"doi\", \"authors\"]\n",
    "            try:\n",
    "                df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)\n",
    "            except:\n",
    "                print(\"Error in removing columns\")\n",
    "            \n",
    "            # Save back to the same file\n",
    "            df['category']= filename\n",
    "            df.to_csv(filepath, index=False)\n",
    "            print(\"Number of instances in \"+filename, len(df))\n",
    "            master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "print(\"Pubmed Data:\")\n",
    "master_df.to_csv('data/all_pubmed.csv', index=False)\n",
    "print(\"all_pubmed\",len(master_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
